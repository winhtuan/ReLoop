from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time

# 1Ô∏è‚É£ C·∫•u h√¨nh Chrome
chrome_options = Options()
chrome_options.add_argument('--ignore-certificate-errors')
chrome_options.add_argument('--disable-blink-features=AutomationControlled')
chrome_options.add_argument('--headless')
chrome_options.add_argument('--window-size=1920,1080')
chrome_options.add_argument('--disable-gpu')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-extensions')

# 2Ô∏è‚É£ Kh·ªüi t·∫°o tr√¨nh duy·ªát
driver = webdriver.Chrome(service=Service(), options=chrome_options)

try:
    # 3Ô∏è‚É£ Truy c·∫≠p trang web
    url = "https://www.chotot.com/mua-ban-may-anh-may-quay-da-nang"#thay duong dan cho nay
    driver.get(url)

    # 4Ô∏è‚É£ Ch·ªù danh s√°ch s·∫£n ph·∫©m xu·∫•t hi·ªán
    WebDriverWait(driver, 20).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "a[href*='/mua-ban-may-anh-may-quay']"))#thay cho nay
    )

    # 5Ô∏è‚É£ Cu·ªôn nh·ªè t·ª´ng b∆∞·ªõc ƒë·ªÉ √©p trigger lazy-loading
    page_height = driver.execute_script("return document.body.scrollHeight")
    for y in range(0, page_height, 300):
        driver.execute_script(f"window.scrollTo(0, {y});")
        time.sleep(0.3)

    # 6Ô∏è‚É£ √âp load to√†n b·ªô ·∫£nh lazy-loading
    driver.execute_script("""
        window.IntersectionObserver = undefined;
        document.querySelectorAll('img').forEach(img => {
            ['data-src', 'data-srcset', 'data-lazy-src'].forEach(attr => {
                if (img.hasAttribute(attr)) {
                    img.setAttribute('src', img.getAttribute(attr));
                    img.removeAttribute(attr);
                }
            });
            if (img.hasAttribute('data-srcset')) {
                img.setAttribute('srcset', img.getAttribute('data-srcset'));
                img.removeAttribute('data-srcset');
            }
            img.loading = 'eager';
            img.removeAttribute('lazy');
        });
    """)
    time.sleep(3)

    # 7Ô∏è‚É£ L·∫•y HTML ƒë·∫ßy ƒë·ªß
    html = driver.page_source

finally:
    # 8Ô∏è‚É£ ƒê√≥ng tr√¨nh duy·ªát
    driver.quit()

# 9Ô∏è‚É£ Ph√¢n t√≠ch HTML b·∫±ng BeautifulSoup
soup = BeautifulSoup(html, "html.parser")
product_links = soup.find_all("a", attrs={"itemprop": "item"})

# üîü M·ªü file ƒë·ªÉ ghi d·ªØ li·ªáu
with open("D:\\ReLoop_Project\\product_sample.txt", "a", encoding="utf-8") as f:
    for product in product_links:
        try:
            img_tag = product.find('img')
            image_url = "Kh√¥ng c√≥"
            if img_tag:
                image_url = img_tag.get('src') or img_tag.get('srcset') or "Kh√¥ng c√≥"
                if ',' in image_url:
                    image_url = image_url.split(',')[0].strip().split(' ')[0]

            title_tag = product.find('h3')
            title = title_tag.get_text(strip=True) if title_tag else "Kh√¥ng c√≥"

            price_tag = product.find('span', class_='bfe6oav')
            price = price_tag.get_text(strip=True) if price_tag else "Kh√¥ng c√≥"

            location_tag = product.find('span', string=lambda x: x and 'Qu·∫≠n' in x)
            location = location_tag.get_text(strip=True) if location_tag else "Kh√¥ng c√≥"

            # Ghi v√†o file
            f.write(f"H√¨nh ·∫£nh: {image_url}\n")
            f.write(f"T√™n: {title}\n")
            f.write(f"Gi√°: {price}\n")
            f.write(f"V·ªã tr√≠: {location}\n")
            f.write("----------\n")
        except Exception as e:
            f.write(f"L·ªói khi x·ª≠ l√Ω m·ªôt s·∫£n ph·∫©m: {e}\n")
            f.write("----------\n")
